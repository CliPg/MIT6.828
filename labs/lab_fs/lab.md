# 大文件（中等难度）

本次作业中，您将增加 xv6 文件的最大大小。目前，xv6 文件的大小限制为 268 个块，即 268 * BSIZE 字节（xv6 中 BSIZE 为 1024）。此限制源于 xv6 inode 包含 12 个“直接”块号和一个“单间接”块号，后者指的是一个最多可容纳 256 个额外块号的块，因此总共有 12 + 256 = 268 个块。

bigfile 命令创建了它能够创建的最大文件，并报告了文件大小：

$ bigfile
..
wrote 268 blocks
bigfile: file is too small
$
测试失败，因为 bigfile 预期能够创建一个包含 65803 个块的文件，但未修改的 xv6 将文件大小限制为 268 个块。

您将修改 xv6 文件系统代码，使其在每个 inode 中支持一个“双重间接”块，该块包含 256 个单间接块的地址，每个单间接块最多可以包含 256 个数据块的地址。这样一来，一个文件最多可以包含 65803 个块，即 256*256+256+11 个块（之所以是 11 个而不是 12 个，是因为我们将牺牲一个直接块号来容纳双重间接块）。

**准备工作**

mkfs 程序用于创建 xv6 文件系统磁盘映像，并确定文件系统的总块数；该大小由 kernel/param.h 中的 FSSIZE 控制。您会发现本实验代码库中的 FSSIZE 设置为 200,000 个块。你应该在 make 的输出中看到 mkfs/mkfs 的以下输出：

nmeta 70 (boot, super, log blocks 30 inode blocks 13, bitmap blocks 25) blocks 199930 total 200000

这一行描述了 mkfs/mkfs 构建的文件系统：它有 70 个元数据块（用于描述文件系统的块）和 199,930 个数据块，总共 200,000 个块。

如果在实验过程中你需要从头开始重建文件系统，可以运行 make clean 命令，强制 make 重建 fs.img。

**需要关注的内容**

磁盘上 inode 的格式由 fs.h 中的 struct dinode 定义。你需要特别关注 NDIRECT、NINDIRECT、MAXFILE 以及 struct dinode 的 addrs[] 元素。请参阅 xv6 教材中的图 8.3，了解标准 xv6 inode 的示意图。

在磁盘上查找文件数据的代码位于 fs.c 文件中的 bmap() 函数中。请查看该函数，并确保您理解其功能。bmap() 函数在读取和写入文件时都会被调用。写入文件时，bmap() 会根据需要分配新的数据块来保存文件内容，并在需要时分配间接数据块来保存块地址。

bmap() 函数处理两种类型的块号。bn 参数是“逻辑块号”——即相对于文件起始位置的文件内块号。ip->addrs[] 数组中的块号以及 bread() 函数的参数是磁盘块号。您可以将 bmap() 函数理解为将文件的逻辑块号映射到磁盘块号。

**您的任务**

修改 bmap() 函数，使其除了直接块和单间接块之外，还实现双间接块。为了给新的双重间接块腾出空间，你只需要 11 个直接块，而不是 12 个；你不能更改磁盘上 inode 的大小。ip->addrs[] 的前 11 个元素应该是直接块；第 12 个元素应该是单间接块（就像当前的块一样）；第 13 个元素应该是你的新的双重间接块。当 bigfile 写入 65803 个块并且 usertests -q 成功运行时，你就完成了这个练习：

$ bigfile

..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
写入了 65803 个块
完成；成功

$ usertests -q

...
所有测试通过

$ bigfile 至少需要一分半钟才能运行。

提示：

确保你理解 `bmap()` 函数。画出 `ip->addrs[]`、间接块、双重间接块及其指向的单次间接块以及数据块之间的关系图。确保你理解为什么添加一个双重间接块会使最大文件大小增加 256*256 个块（实际上是 -1，因为你必须将直接块的数量减少一个）。

思考如何使用逻辑块号来索引双重间接块及其指向的间接块。

如果你更改了 `NDIRECT` 的定义，你可能需要更改 `file.h` 中 `struct inode` 中 `addrs[]` 的声明。确保 `struct inode` 和 `struct dinode` 的 `addrs[]` 数组中的元素数量相同。

如果你更改了 `NDIRECT` 的定义，请确保创建一个新的 `fs.img` 文件，因为 `mkfs` 函数会修改 `NDIRECT` 的定义。


# 符号链接（中等难度）

在本练习中，您将向 xv6 添加符号链接。符号链接（或软链接）通过路径名指向链接的文件；当打开一个符号链接时，内核会跟随该链接找到被链接的文件。符号链接类似于硬链接，但硬链接只能指向同一磁盘上的文件，而符号链接可以跨磁盘设备。尽管 xv6 不支持多设备访问，但实现此系统调用是理解路径名查找工作原理的好方法。

**您的任务**

您需要实现 `symlink(char *target, char *path)` 系统调用，该调用会在 `path` 处创建一个指向名为 `target` 的文件的符号链接。更多信息，请参阅 `symlink` 的手册页。要进行测试，请在 Makefile 中添加 `symlinktest` 并运行它。当测试产生以下输出（包括用户测试成功）时，您的解决方案即完成。

$ symlinktest
Start: test symlinks
test symlinks: ok
Start: test concurrent symlinks
test concurrent symlinks: ok
$ usertests -q
...
ALL TESTS PASSED
$ 

...

所有测试通过

提示：

首先，为符号链接创建一个新的系统调用号，在 user/usys.pl 和 user/user.h 中添加条目，并在 kernel/sysfile.c 中实现一个空的 sys_symlink。

在 kernel/stat.h 中添加一个新的文件类型 (T_SYMLINK) 来表示符号链接。

在 kernel/fcntl.h 中添加一个新的标志 (O_NOFOLLOW)，该标志可以与 open 系统调用一起使用。请注意，传递给 open 的标志使用按位或运算符组合，因此您的新标志不应与任何现有标志重叠。这样，在将 user/symlinktest.c 添加到 Makefile 后，您就可以编译它了。

实现 `symlink(target, path)` 系统调用，在路径 `path` 处创建一个指向目标文件 `target` 的新符号链接。注意，即使目标文件不存在，系统调用也能成功。你需要选择一个地方来存储符号链接的目标路径，例如，存储在 inode 的数据块中。`symlink` 应该返回一个整数，表示成功 (0) 或失败 (-1)，类似于 `link` 和 `unlink` 函数。

修改 `open` 系统调用，使其能够处理路径指向符号链接的情况。如果文件不存在，`open` 必须失败。当进程在 `open` 的标志中指定 `O_NOFOLLOW` 时，`open` 应该打开符号链接（而不是跟随符号链接）。

如果链接的文件也是一个符号链接，你必须递归地跟随它，直到找到一个非链接文件。如果链接形成循环，你必须返回一个错误代码。你可以通过在链接深度达到某个阈值（例如 10）时返回错误代码来近似实现这一点。

其他系统调用（例如 link 和 unlink）不能跟随符号链接；这些系统调用直接操作符号链接本身。

本实验无需处理指向目录的符号链接。